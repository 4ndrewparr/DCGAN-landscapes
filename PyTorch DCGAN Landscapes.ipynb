{"cells":[{"metadata":{},"cell_type":"markdown","source":"sources:  \nhttps://arxiv.org/abs/1511.06434  - 'Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks'  \nhttps://github.com/pytorch/examples/blob/master/dcgan/main.py - PyTorch implementation of the paper\n\n\n\n\nchanges made:\n- **Doubled image size** - now 128x128 instead of 64x64 (adding a layer in both networks)\n- **Unbalanced G/D channels** - ngf=160/ndf=40 instead of ngf=64/ndf=64 (gives an advantage to the generator) \n- **subtitutes arguments** (command prompt oriented) with hardcoded variables (notebook oriented)\n- **checkpoint** to resume training (Kaggle CPU kernels time limit is 9 hours, which is around 50 epochs)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport sys\nimport os\nimport torch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('../input')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checkpoint\n\nEPOCH_START = 650 # index value\n\n\ncuda = torch.cuda.is_available()\nmap_location = None if cuda else 'cpu' # needed only if saved in gpu but loaded in cpu\n\n#ckpt = 0\nckpt = torch.load(f'../input/d-dcgan-barrat-pytorch-my-landscapes-{EPOCH_START}e/checkpoint.tar', map_location=map_location)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hardcoded variables\n\nWORKERS = 2 # number of data loading workers\n#NGPU = 1 # number of GPUs to use (paralel processing)\n\nNC = 3\nBATCHSIZE = 64\nIMAGESIZE = 128\nNZ = 100 # size of the latent z vector\nNGF = 160 # number of generator feature maps after 'first' conv\nNDF = 40 # number of discriminator feature maps after 'first' conv\n\nEPOCHS = 50 # number of epochs to train for\nLR = 0.0002\nBETA1 = 0.5\nBETA2 = 0.999\nMANUALSEED = None # if None, randomly generated\n\nDATAROOT = '../input'\nPATH_OUT = '.' # folder to output images and model checkpoints\nPATH_SAMPLES = f'{PATH_OUT}/samples'\nPATH_FINAL = f'{PATH_OUT}/final'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from __future__ import print_function\nimport argparse\nimport os\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\n\n\n\n\n# seeding\n\nif MANUALSEED is None:\n    MANUALSEED = random.randint(1, 10000)\nprint(\"Random Seed: \", MANUALSEED)\nrandom.seed(MANUALSEED)\ntorch.manual_seed(MANUALSEED)\n\n\n\n# device\n\ndevice = torch.device(\"cuda:0\" if cuda else \"cpu\")\ncudnn.benchmark = True ## kind of a cudnn auto-tuner, useful when inputs size dont vary\n\n    \n# data\n\ndataset = dset.ImageFolder(root=DATAROOT,\n                           transform=transforms.Compose([\n                           ##    transforms.Resize(opt.imageSize), ## done outside of notebook\n                           ##    transforms.CenterCrop(opt.imageSize), ## done outside of notebook\n                               transforms.ToTensor(),\n                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), ## sequences of means, stds for each channel\n                               \n                           ])\n                            )\n## ImageFolder returns (sample, target) where target is class_index of the target class.\n## Images are expected to be sorted in class folders, so any folder with images in root is considered a class,\n## thus when calling dataloader, it returns a list of a batch of images and a batch of 'labels', in this case folder indexes.\n\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCHSIZE,\n                                         drop_last=True, ##\n                                         shuffle=True, num_workers=WORKERS)\n\n\n\n# custom weights initialization called on netG and netD\n\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        m.weight.data.normal_(0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        m.bias.data.fill_(0)\n        \n        \n#######        \n## G ##\n#######\n\n# architecture           \n        \nclass Generator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.main = nn.Sequential(\n            ## input size is  NZ x 1 x 1  already so we can convolute over it\n            nn.ConvTranspose2d(     NZ, NGF * 16, 4, 1, 0, bias=False), ## 160 * 16 = 2,560 channels\n            nn.BatchNorm2d(NGF * 16),\n            nn.ReLU(True),\n            # state size. (NGF*16) x 4 x 4                                  \n            nn.ConvTranspose2d(NGF * 16, NGF * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(NGF * 8),\n            nn.ReLU(True),\n            # state size. (NGF*8) x 8 x 8\n            nn.ConvTranspose2d(NGF * 8, NGF * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(NGF * 4),\n            nn.ReLU(True),\n            # state size. (NGF*4) x 16 x 16\n            nn.ConvTranspose2d(NGF * 4, NGF * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(NGF * 2),\n            nn.ReLU(True),\n            # state size. (NGF*2) x 32 x 32\n            nn.ConvTranspose2d(NGF * 2,     NGF, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(NGF),\n            nn.ReLU(True),\n            # state size. (NGF) x 64 x 64\n            nn.ConvTranspose2d(    NGF,      NC, 4, 2, 1, bias=True), ## bias True here since no BN follows\n            nn.Tanh()\n            # state size. (NC) x 128 x 128\n        )\n\n    def forward(self, input):\n        output = self.main(input) \n        \n        return output\n\n    \n    \n# instantiating and initializing/loading weights\n\nnetG = Generator().to(device)\nif ckpt:\n    netG.load_state_dict(ckpt['G_state_dict'])\n    print('Resuming training... G weights loaded')\nelse:\n    netG.apply(weights_init)\n##print(netG)\n\n\n#######        \n## D ##\n#######\n\n# architecture   \n\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.main = nn.Sequential(\n            # input is (NC) x 128 x 128\n            nn.Conv2d(NC, NDF, 4, 2, 1, bias=False), ## shouldnt bias be True since BN is not applied ?\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (NDF) x 64 x 64\n            nn.Conv2d(NDF, NDF * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(NDF * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size.NDF*2) x 32 x 32\n            nn.Conv2d(NDF * 2, NDF * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(NDF * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (NDF*4) x 16 x 16\n            nn.Conv2d(NDF * 4, NDF * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(NDF * 8),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size.(NDF*8) x 8 x 8\n            nn.Conv2d(NDF * 8, NDF * 16, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(NDF * 16),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (NDF*16) x 4 x 4\n            nn.Conv2d(NDF * 16, 1, 4, 1, 0, bias=True), ## bias True here since no BN follows\n            ## kernel_size=4x4, no padding, 1 output channel => reduction to a single unit output\n            ## state size. (1) x 1 x 1\n            nn.Sigmoid()\n        )\n\n    def forward(self, input):    \n        output = self.main(input) ## (BATCHSIZE x 1 x 1 x 1)\n\n        return output.view(-1) ## (BATCHSIZE)\n\n\n# instantiating and initializing/loading weights\n\nnetD = Discriminator().to(device)\nif ckpt:\n    netD.load_state_dict(ckpt['D_state_dict'])\n    print('Resuming training... D weights loaded')\nelse:\n    netD.apply(weights_init)\n##print(netD)\n\n\n\n##############        \n## TRAINING ##\n##############\n\n\noptimizerD = optim.Adam(netD.parameters(), lr=LR, betas=(BETA1, BETA2))\noptimizerG = optim.Adam(netG.parameters(), lr=LR, betas=(BETA1, BETA2))\n\n\ncriterion = nn.BCELoss()\nreal_label = 1\nfake_label = 0\nlogs = {'errD': ckpt['logs']['errD'] if ckpt else [],\n        'errG': ckpt['logs']['errG'] if ckpt else [],\n        'D_x': ckpt['logs']['D_x'] if ckpt else [],\n        'D_G_z1': ckpt['logs']['D_G_z1']if ckpt else [],\n        'D_G_z2': ckpt['logs']['D_G_z2'] if ckpt else [],\n        'batch': ckpt['logs']['batch'] if ckpt else [],\n        'epoch': ckpt['logs']['epoch'] if ckpt else [],\n       }\nbatch_start = logs['batch'][-1] if ckpt else 0\nfixed_noise = torch.randn(BATCHSIZE, NZ, 1, 1, device=device) ## same every time we sample to see the progress, size=(BATCHSIZE, NZ, 1, 1)\nos.makedirs(PATH_SAMPLES, exist_ok=True)\n\nfor epoch in range(EPOCHS):                \n    for i, (data, _) in enumerate(dataloader):   \n        \n        ############################\n        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n        ###########################\n        # train with real      \n        netD.zero_grad()\n        real_images = data.to(device)\n        label = torch.full((BATCHSIZE,), real_label, device=device) ## drop_last=True added to dataloader\n        output = netD(real_images)\n        D_x = output.mean().item() ## metrics        \n        errD_real = criterion(output, label)\n        \n        errD_real.backward() ##\n\n        # train with fake\n        noise = torch.randn(BATCHSIZE, NZ, 1, 1, device=device) ## normal noise (uniform noise is another option but it is not recommended)\n        fake = netG(noise)\n        label.fill_(fake_label)\n        output = netD(fake.detach()) ## .detach() 'freezes' the weights of netG (detaches from the graph fake)       \n        ## actually, since optimizerD only updates netD parameters and netG.zero_grad() is called before errG.backward(), this just avoids fake to be cleared after\n        ## the backward pass (it is needed later for G training), plus it is faster/more efficient. This also explains why no freezing is applied later when training G\n        D_G_z1 = output.mean().item() ## metrics        \n        errD_fake = criterion(output, label)\n        errD = (errD_real + errD_fake)/2 ## metrics\n        \n        \n        errD_fake.backward()\n        \n        optimizerD.step()\n\n        ############################\n        # (2) Update G network: maximize log(D(G(z)))\n        ###########################\n        netG.zero_grad()\n        label.fill_(real_label)  # fake labels are real for generator cost\n        output = netD(fake)\n        D_G_z2 = output.mean().item() ## metrics\n        errG = criterion(output, label)\n        \n        errG.backward()        \n\n        optimizerG.step()\n\n\n            \n        batches_done = epoch * len(dataloader) + i ##\n        \n        #if i % 1 == 0: ## testing\n        if batches_done % 50 == 0: ## ~ each two epochs  \n            \n            # output log print\n            \n            log_string = (f'[{epoch+EPOCH_START:03d}/{EPOCHS+EPOCH_START:02d}][{i:02d}/{len(dataloader):03d}]'\n                         f'\\tLoss_D: {errD.item():.4f}  Loss_G: {errG.item():.4f}'\n                         f'\\t\\tD(x): {D_x:.4f}  D(G(z)): {D_G_z1:.4f}>>{D_G_z2:.4f}')\n           \n            print(log_string, end='\\r') ##\n            #sys.stdout.write(log_string)\n            \n\n            # save image samples\n            \n            fake = netG(fixed_noise)\n            vutils.save_image(fake.detach()[:9], ##\n                    f'{PATH_SAMPLES}/fake_{batches_done:05d}_{epoch+EPOCH_START:03d}.png', ##\n                    nrow=3, ##\n                    normalize=True)\n            \n            # logs\n            \n            logs['errD'] += [errD.item()] # errD is a Tensor\n            logs['errG'] += [errG.item()] # errG is a Tensor\n            logs['D_x'] += [D_x]\n            logs['D_G_z1'] += [D_G_z1]\n            logs['D_G_z2'] += [D_G_z2]\n            logs['batch'] += [batches_done+batch_start]\n            logs['epoch'] += [epoch+EPOCH_START]\n        \n\n# checkpoint\n\ntorch.save({\n    'D_state_dict': netD.state_dict(),\n    'G_state_dict': netG.state_dict(),\n    'D_optimizer_state_dict': optimizerD.state_dict(),    \n    'G_optimizer_state_dict': optimizerG.state_dict(),\n    'logs': logs,\n}, f'{PATH_OUT}/checkpoint.tar') # .tar is the pytorch convention for dictionaries","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## plot losses\n\nplt.figure(figsize=(10,10))\nplt.axvline(x=batch_start, c='k', linewidth=1)\nplt.plot(logs['batch'], logs['errD'], 'b-', linewidth=1, label='discriminator')\nplt.plot(logs['batch'], logs['errG'], 'r-', linewidth=1, label='generator')\n#plt.legend()\nplt.title('Losses')\n\n# secondary x axis (more correct is ax.secondary_xaxis but N/A in this matplotlib version)\nax = plt.gca()\nax2 = ax.twiny()\nax2.plot(logs['epoch'], logs['errD'], 'k-', alpha=0.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## plot predictions\n\nplt.figure(figsize=(10,10))\nplt.axvline(x=batch_start, c='k', linewidth=1)\nplt.plot(logs['batch'], logs['D_x'], 'b-', linewidth=1, label='real')\nplt.plot(logs['batch'], logs['D_G_z1'], '-', c='orange', linewidth=1, label='fake1')\nplt.plot(logs['batch'], logs['D_G_z2'], 'r-', linewidth=1, label='fake2')\n#plt.legend()\nplt.title('Discriminator predictions')\n\n# secondary x axis (more correct is ax.secondary_xaxis but N/A in this matplotlib version)\nax = plt.gca()\nax2 = ax.twiny()\nax2.plot(logs['epoch'], logs['D_x'], 'k-', alpha=0.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## training process images\n\nsorted_images = sorted(os.listdir(PATH_SAMPLES))\n\nn_images = len(sorted_images)\n#n_images = 7\n\n#rows, columns = 3, 3\ncolumns = 3\nrows = np.ceil(n_images/columns) \n\nfig = plt.figure(figsize=(40, 40*rows/columns)) # in order to fill notebook width\nfig.subplots_adjust(hspace=.05, wspace=0)\nax = [] # axes objects (plotting)\n\nfor i, file_name in enumerate(sorted_images):\n    img = Image.open(f'{PATH_SAMPLES}/{file_name}')\n    ax.append(fig.add_subplot(rows, columns, i+1))\n    #ax[-1].grid(False) # not needed\n    ax[-1].set_xticks([])\n    ax[-1].set_yticks([])\n    ax[-1].title.set_text(file_name)\n    ax[-1].title.set_fontsize(25)\n    plt.imshow(img) # only shown with this","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## final images\n\n\nos.makedirs(PATH_FINAL, exist_ok=True)\n\nvutils.save_image(real_images[:25], ##           \n        f'{PATH_FINAL}/real.png',\n        nrow=5, ##\n        normalize=True)\nfake = netG(fixed_noise)\nvutils.save_image(fake.detach()[:25],\n        f'{PATH_FINAL}/fake.png', ##\n        nrow=5, ##\n        normalize=True)\n\n\nsorted_images = os.listdir(PATH_FINAL)\nn_images = len(sorted_images)\n\nrows, columns = 1, 2\n\nfig = plt.figure(figsize=(40, 40*rows/columns)) # figure object\nfig.subplots_adjust(hspace=.05, wspace=0)\nax = [] # axes objects (plotting)\n\nfor i, file_name in enumerate(sorted_images):\n    img = Image.open(f'{PATH_FINAL}/{file_name}')\n    ax.append(fig.add_subplot(rows, columns, i+1))\n    #ax[-1].grid(False) # not needed\n    ax[-1].set_xticks([])\n    ax[-1].set_yticks([])\n    ax[-1].title.set_text(file_name)\n    ax[-1].title.set_fontsize(50)\n    plt.imshow(img) # only shown with this","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}